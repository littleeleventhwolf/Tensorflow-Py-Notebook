{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可视化是认识程序的最直观方式。在做数据分析时，可视化一般是数据分析最后一步的结果呈现。把可视化放到“基础篇”，是为了让读者在安装完成后，就能先看一下TensorFlow到底有哪些功能，直观感受一下深度学习的学习成果，让学习目标一目了然。\n",
    "\n",
    "## 3.1 PlayGround\n",
    "\n",
    "PlayGround是一个用于教学目的的简单神经网络的在线演示、实验的图形化平台，非常强大地可视化了神经网络的训练过程。使用它可以在浏览器里训练神经网络，对TensorFlow有一个感性的认识。\n",
    "\n",
    "PlayGround界面从左到右由数据（DATA）、特征（FEATURES）、神经网络的隐藏层（HIDDEN LAYERS）和层中的连接线和输出（OUTPUT）几个部分组成，如图3-1所示。\n",
    "\n",
    "![3-1](3-attach/3-1.png)\n",
    "\n",
    "### 3.1.1 数据\n",
    "\n",
    "在二维平面内，点被标记成两种颜色。深色（电脑屏幕显示为蓝色）代表正值，浅色（电脑屏幕显示为黄色）代表负值。这两种颜色表示想要区分的两类，如图3-2所示。\n",
    "\n",
    "![3-2](3-attach/3-2.png)\n",
    "\n",
    "网站提供了4种不同形态的数据，分别是圆形、异或、高斯和螺旋，如图3-3所示。神经网络会根据所给的数据进行训练，再分类规律相同的点。\n",
    "\n",
    "![3-3](3-attach/3-3.png)\n",
    "\n",
    "PlayGround中的数据配置非常灵活，可以调整噪声（noise）的大小。图3-4展示的是噪声为0、25和50时的数据分布。\n",
    "\n",
    "![3-4](3-attach/3-4.png)\n",
    "\n",
    "PlayGround中也可以改变训练数据和测试数据的比例（ratio）。图3-5展示的是训练数据和测试数据比例为1:9和9:1时的情况。\n",
    "\n",
    "![3-5](3-attach/3-5.png)\n",
    "\n",
    "此外，PlayGround中还可以调整输入的每批（batch）数据的多少，调整范围可以是1～30，就是说每批进入神经网络数据的点可以是1～30个，如图3-6所示。\n",
    "\n",
    "![3-6](3-attach/3-6.png)\n",
    "\n",
    "### 3.1.2 特征\n",
    "\n",
    "接下来我们需要做特征提取（feature extraction），每一个点都有$X_1$和$X_2$两个特征，由这两个特征还可以衍生出许多其他特征，如$X_1X_1$、$X_2X_2$、$X_1X_2$、$\\sin\\left(X_1\\right)$、$\\sin\\left(X_2\\right)$等，如图3-7所示。\n",
    "\n",
    "![3-7](3-attach/3-7.png)\n",
    "\n",
    "从颜色上，$X_1$左边浅色（电脑屏幕显示为黄色）是负，右边深色（电脑屏幕显示为蓝色）是正，$X_1$表示此点的横坐标值。同理，$X_2$上边深色是正，下边浅色是负，$X_2$表示此点的纵坐标值。$X_1X_1$是关于横坐标的“抛物线”信息，$X_2X_2$是关于纵坐标的“抛物线”信息，$X_1X_2$是“双曲抛物线”的信息，$\\sin\\left(X_1\\right)$是关于横坐标的“正弦函数”信息，$\\sin\\left(X_2\\right)$是关于纵坐标的“正弦函数”信息。\n",
    "\n",
    "因此，我们要学习的分类器（classifier）就是要结合上述一种或者多种特征，画出一条或者多条线，把原始的蓝色和黄色数据分开。\n",
    "\n",
    "### 3.1.3 隐藏层\n",
    "\n",
    "我们可以设置隐藏层的多少，以及每个隐藏层神经元的数量，如图3-8所示。\n",
    "\n",
    "![3-8](3-attach/3-8.png)\n",
    "\n",
    "隐藏层之间的连接线表示权重（weight），深色（蓝色）表示用神经元的原始输出，浅色（黄色）表示用神经元的负输出。连接线的粗细和深浅表示权重的绝对值大小。鼠标放在线上可以看到具体值，也可以修改值，如图3-9所示。\n",
    "\n",
    "![3-9](3-attach/3-9.png)\n",
    "\n",
    "修改值时，同时要考虑激活函数，例如，当换成Sigmoid时，会发现没有负向的黄色区域了，因为Sigmoid的值域是$\\left(0,1\\right)$，如图3-10所示。\n",
    "\n",
    "![3-10](3-attach/3-10.png)\n",
    "\n",
    "下一层神经网络的神经元会对这一层的输出再进行组合。组合时，根据上一次预测的准确性，我们会通过反向传播给每个组合不同的权重。组合时连接线的粗细和深浅会发生变化，连接线的颜色越深越粗，表示权重越大。\n",
    "\n",
    "### 3.1.4 输出\n",
    "\n",
    "输出的目的是使黄色点都归于黄色背景，蓝色点都归于蓝色背景，背景颜色的深浅代表可能性的强弱。\n",
    "\n",
    "我们选定螺旋形数据，7个特征全部输入，进行试验。选择只有3个隐藏层时，第一个隐藏层设置8个神经元，第二个隐藏层设置4个神经元，第三个隐藏层设置2个神经元。训练大概2分钟，测试损失（test loss）和训练损失（training loss）就不再下降了。训练完成时可以看出，我们的神经网络已经完美地分离出了黄色点和蓝色点，如图3-11所示。\n",
    "\n",
    "![3-11](3-attach/3-11.png)\n",
    "\n",
    "假设我们只输入最基本的前4个特征，给足多个隐藏层，看看神经网络的表现。假设加入6个隐藏层，前4层每层有8个神经元，第五层有6个神经元，第六层有2个神经元。结果如图3-12所示。\n",
    "\n",
    "![3-12](3-attach/3-12.png)\n",
    "\n",
    "我们发现，通过增加神经元的个数和神经网络的隐藏层数，即使没有输入许多特征，神经网络也能正确地分类。但是，假如我们要分类的物体是猫猫狗狗的图片，而不是肉眼能够直接识别出特征的黄点和蓝点呢？这时候怎样去提取那些真正有效的特征呢？\n",
    "\n",
    "有了神经网络，我们的系统自己就能学习到哪些特征是有效的、哪些特征是无效的，通过自己学习的这些特征，就可以做到自己分类，这就大大提高了我们解决语音、图像这种复杂抽象问题的能力。\n",
    "\n",
    "## 3.2 TensorBoard\n",
    "\n",
    "TensorBoard是TensorFlow自带的一个强大的可视化工具，也是一个Web应用程序套件。TensorBoard目前支持7种可视化，即SCALARS、IMAGES、AUDIO、GRAPHS、DISTRIBUTIONS、HISTOGRAMS和EMBEDDINGS。这7种可视化的主要功能如下。\n",
    "\n",
    "* SCALARS：展示训练过程中的准确率、损失值、权重/偏置的变化情况。\n",
    "* IMAGES：展示训练过程中记录的图像。\n",
    "* AUDIO：展示训练过程中记录的音频。\n",
    "* GRAPHS：展示模型的数据流图，以及训练在各个设备上消耗的内存和时间。\n",
    "* DISTRIBUTIONS：展示训练过程中记录的数据的分布图。\n",
    "* HISTOGRAMS：展示训练过程中记录的数据的柱状图。\n",
    "* EMBEDDINGS：展示词向量（如word2vec）后的投影分布。\n",
    "\n",
    "TensorBoard通过运行一个本地服务器，来监听6006端口。在浏览器发出请求时，分析训练时记录的数据，绘制训练过程中的图像。在9.3节的MNIST示例中，会逐一讲解TensorBoard的图像绘制，让读者更好地了解训练的过程中发生了什么。本节我们就先看一下TensorBoard能够绘制出哪些东西。\n",
    "\n",
    "TensorBoard的可视化界面如图3-13所示。\n",
    "\n",
    "![3-13](3-attach/3-13.png)\n",
    "\n",
    "从图3-13中可以看到，在标题处有上述几个可视化面板，下面通过一个示例，分别介绍这些可视化面板的功能。\n",
    "\n",
    "这里，我们运行手写数字识别的入门例子，如下：\n",
    "\n",
    "```\n",
    "python tensorflow-1.1.0/tensorflow/examples/tutorials/mnist/mnist_with_summaries.py\n",
    "```\n",
    "\n",
    "然后，打开TensorBoard面板：\n",
    "\n",
    "```\n",
    "tensorboard --logdir=/tmp/mnist/logs/mnist_with_summaries\n",
    "```\n",
    "\n",
    "这时，输出：\n",
    "\n",
    "```\n",
    "Starting TensorBoard 39 on port 6006\n",
    "(You can navigate to http://localhost.localdomain:6006)\n",
    "```\n",
    "\n",
    "我们就可以在浏览器中打开```http://localhost.localdomain:6006```，查看面板的各项功能。\n",
    "\n",
    "### 3.2.1 SCALARS面板\n",
    "\n",
    "SCALARS面板的左边是一些选项，包括Split on undercores（用下划线分开显示）、Data downloadlinks（数据下载链接）、Smoothing（图像的曲线平滑程度）以及Horizontal Axis（水平轴）的表示，其中水平轴的表示分3种（STEP代表迭代次数，RELATIVE代表按照训练集和测试集的相对值，WALL代表按照时间），如图3-14左边所示。图3-14右边给出了准确率和交叉熵损失函数值的变化曲线（迭代次数是1000次）。\n",
    "\n",
    "![3-14](3-attach/3-14.png)\n",
    "\n",
    "SCALARS面板中还绘制了每一层的偏置（biases）和权重（weights）的变化曲线，包括每次迭代中的最大值、最小值、平均值和标准差，如图3-15所示。\n",
    "\n",
    "![3-15](3-attach/3-15.png)\n",
    "\n",
    "### 3.2.2 IMAGES面板\n",
    "\n",
    "图3-16展示了训练数据集和测试数据集经过预处理后图片的样子。\n",
    "\n",
    "![3-16](3-attach/3-16.png)\n",
    "\n",
    "### 3.2.3 AUDIO面板\n",
    "\n",
    "AUDIO面板是展示训练过程中处理的音频数据。这里暂时没有找到合适的例子，读者了解即可。\n",
    "\n",
    "### 3.2.4 GRAPHS面板\n",
    "\n",
    "GRAPHS面板是对理解神经网络结构最有帮助的一个面板，它直观地展示了数据流图。图3-17所示界面中节点之间的连线即为数据流，连线越粗，说明在两个节点之间流动的张量（tensor）越多。\n",
    "\n",
    "![3-17](3-attach/3-17.png)\n",
    "\n",
    "在GRAPHS面板的左侧，可以选择迭代步骤。可以用不同Color（颜色）来表示不同的Structure（整个数据流图的结构），或者用不同Color来表示不同Device（设备）。例如，当使用多个GPU时，各个节点分别使用的GPU不同。\n",
    "\n",
    "当我们选择特定的某次迭代（如第899次）时，可以显示出各个节点的Compute time（计算时间）以及Memory（内存消耗），如图3-18所示。\n",
    "\n",
    "![3-18](3-attach/3-18.png)\n",
    "\n",
    "### 3.2.5 DISTRIBUTIONS面板\n",
    "\n",
    "DISTRIBUTIONS面板和接下来要讲的HISTOGRAMS面板类似，只不过是用平面来表示来自特定层的激活前后、权重和偏置的分布。图3-19展示的是激活之前和激活之后的数据分布。\n",
    "\n",
    "![3-19](3-attach/3-19.png)\n",
    "\n",
    "### 3.2.6 HISTOGRAMS面板\n",
    "\n",
    "HISTOGRAMS主要是立体地展现来自特定层的激活前后、权重和偏置的分布。图3-20展示的是激活之前和激活之后的数据分布。\n",
    "\n",
    "![3-20](3-attach/3-20.png)\n",
    "\n",
    "### 3.2.7 EMBEDDINGS面板\n",
    "\n",
    "EMBEDDINGS面板在MNIST这个示例中无法展示，在3.3节中我们会用word2vec例子来看一下这个面板的词嵌入投影仪。\n",
    "\n",
    "## 3.3 可视化的例子\n",
    "\n",
    "词嵌入（word embedding）在机器学习中非常常见，可以应用在自然语言处理、推荐系统等其他程序中。下面我们就以word2vec为例来看看词嵌入投影仪的可视化。\n",
    "\n",
    "TensorFlow的word2vec有basic、optimised这两个版本，我们重点来看这两个版本的可视化表示。\n",
    "\n",
    "### 3.3.1 降维分析\n",
    "\n",
    "本节将以GitHub上的一段代码为例，讲述可视化的思路。\n",
    "\n",
    "word2vec采用text8作为文本的训练数据集。这个文本中只包含了a～z字符和空格，共27种字符。我们重点讲述产生的结果可视化的样子以及构建可视化的过程。这里我们采用的是skip-gram模型，即根据目标词汇预测上下文。也就是说，给定$n$个词围绕着词$w$，用$w$来预测一个句子中其中一个缺漏的词$c$，以概率$p\\left(c|w\\right)$来表示。最后生成的用t-SNE降维呈现词汇接近程度的关系如图3-21所示。\n",
    "\n",
    "![3-21](3-attach/3-21.png)\n",
    "\n",
    "在word2vec_basic.py中，从获得数据到最终得到可视化的结果的过程分为5步。\n",
    "\n",
    "（1）下载文件并读取数据。主要是read_data函数，它读取输入的数据，输出一个list，里面的每一项就是一个词。\n",
    "\n",
    "``` python\n",
    "# Read the data into a list of strings.\n",
    "def read_data(filename):\n",
    "  \"\"\"Extract the first file enclosed in a zip file as a list of words.\"\"\"\n",
    "  with zipfile.ZipFile(filename) as f:\n",
    "    data = tf.compat.as_str(f.read(f.namelist()[0])).split()\n",
    "  return data\n",
    "```\n",
    "\n",
    "这里的data就类似于\\['fawn', 'homomorphism', 'nordisk', 'nunnery'\\]。\n",
    "\n",
    "（2）建立一个词汇字典。这里首先建立了一个词汇字典，字典里是对应的词和这个词的编码。\n",
    "\n",
    "``` python\n",
    "vocabulary_size = 50000\n",
    "\n",
    "def build_dataset(words, n_words):\n",
    "  \"\"\"Process raw inputs into a dataset.\"\"\"\n",
    "  count = [['UNK', -1]]\n",
    "  count.extend(collections.Counter(words).most_common(n_words - 1))\n",
    "  dictionary = dict()\n",
    "  for word, _ in count:\n",
    "    dictionary[word] = len(dictionary)\n",
    "  data = list()\n",
    "  unk_count = 0\n",
    "  for word in words:\n",
    "    index = dictionary.get(word, 0)\n",
    "    if index == 0:  # dictionary['UNK']\n",
    "      unk_count += 1\n",
    "    data.append(index)\n",
    "  count[0][1] = unk_count\n",
    "  reversed_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "  return data, count, dictionary, reversed_dictionary\n",
    "            \n",
    "data, count, dictionary, reverse_dictionary = build_dataset(\n",
    "    vocabulary, vocabulary_size)\n",
    "```\n",
    "\n",
    "dictonary里存储的就是词与这个词的编码；reverse_dictionary是反过来的dictionary，对应的是词的编码与这个词；data是list，存储的是词对应的编码，也就是第一步中得到的词的list，转化为词的编码表示；count中存储的是词汇和词频，其中重复数量少于49,999个词，用'UNK'来代表稀有词。具体示例如下：\n",
    "\n",
    "```\n",
    "data [5239, 3084, 12, 6, 195, 2, 3137, 46, 59, 156]\n",
    "count [['UNK', 418391], ('the', 1061396), ('of', 593677), ('and', 416629),\n",
    "\t   ('one', 411764), ('in', 372201), ('a', 325873), ('to', 316376), ('zero', 264975),\n",
    "       ('nine', 250430)]\n",
    "dictionary {'fawn': 0, 'homomorphism': 1, 'nordisk': 2, 'nunnery': 3, 'chthonic':\n",
    "\t\t\t4, 'sowell': 5, 'sonja': 6, 'showa': 7, 'woods': 8, 'hsv': 9}\n",
    "reverse_dictionary {0: 'fawn', 1: 'homomorphism', 2: 'nordisk', 3: 'nunnery', 4:\n",
    "\t\t\t\t\t  'chthonic', 5: 'sowell', 6: 'sonja', 7: 'showa', 8: 'woods', 9: 'hsv'}\n",
    "```\n",
    "\n",
    "（3）产生一个批次（batch）的训练数据。这里定义generate_batch函数，输入batch_size、num_skips和skip_window，其中batch_size是每个batch的大小，num_skips代表样本的源端要考虑几次，skip_windows代表左右各考虑多少个词，其中skip_windows$\\times$2=num_skips。最后返回的是batch和label，batch的形状是\\[batch_size\\]，label的形状是\\[batch_size, 1\\]，也就是用一个中心词来预测一个周边词。\n",
    "\n",
    "举个例子。假设我们的句子是“我要写一首歌”，我们将每一个字用dictionary中的编码代替，就变成了\\[123, 3084, 12, 6, 195, 90\\]，假设这里的window_size是3，也就是只预测上文一个词，下文一个词，假设我们的generate_batch函数从3084出发，源端重复2次，那么batch就是\\[3084 3084 12 12 6 6 195 195\\]，3084的上文是123，下文是12；12的上文是3084，下文是6；6的上文是12，下文是195；195的上文是6，下文是90。因此，对应输出的label就是：\n",
    "\n",
    "```\n",
    "[[ 123]\n",
    " [  12]\n",
    " [3084]\n",
    " [   6]\n",
    " [  12]\n",
    " [ 195]\n",
    " [   6]\n",
    " [  90]]\n",
    "```\n",
    "\n",
    "（4）构建和训练模型。这里我们构建一个skip-gram模型，具体模型搭建可以参考skip-gram的相关论文。执行结果如下：\n",
    "\n",
    "```\n",
    "Found and verified text8.zip\n",
    "Data size 17005207\n",
    "Most common words (+UNK) [['UNK', 418391], ('the', 1061396), ('of', 593677), ('and', 416629), ('one', 411764)]\n",
    "Sample data [5239, 3084, 12, 6, 195, 2, 3137, 46, 59, 156] ['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse', 'first', 'used', 'against']\n",
    "3084 originated -> 5239 anarchism\n",
    "3084 originated -> 12 as\n",
    "12 as -> 3084 originated\n",
    "12 as -> 6 a\n",
    "6 a -> 12 as\n",
    "6 a -> 195 term\n",
    "195 term -> 2 of\n",
    "195 term -> 6 a\n",
    "Initialized\n",
    "Average loss at step  0 :  274.478088379\n",
    "Nearest to into: transsexualism, customer, cortona, amps, rl, rejuvenated, magicians, extras,\n",
    "Nearest to this: limbs, polytechnique, stamens, optionally, ballantine, lpg, provides, ingres,\n",
    "Nearest to four: spearhead, narrowest, mysticeti, notion, inaugurated, uncovered, coastal, cip,\n",
    "Nearest to with: josiah, pediatrician, campion, designs, stewards, mnp, saunders, marie,\n",
    "Nearest to during: fpss, anointed, baluchistan, computability, pmid, messianic, barley, divination,\n",
    "Nearest to united: mchale, vessel, wherever, compounding, headaches, sadc, winer, harmonic,\n",
    "Nearest to up: megaliths, pronounces, eikon, kamakura, offal, redefining, searches, moore,\n",
    "Nearest to is: babbitt, westernized, surgeon, deforestation, litres, andromache, greenville, circling,\n",
    "Nearest to if: marseille, lava, introductions, overloading, pushes, tristram, decibels, burnside,\n",
    "Nearest to see: tsarist, zapata, lugdunum, siddeley, boac, deprecating, produces, chiefly,\n",
    "Nearest to but: camelcase, gcb, duplicating, agrarian, retrospect, preserved, baggage, vcs,\n",
    "Nearest to of: convention, townships, bea, unusual, arbitrary, themes, honolulu, pontic,\n",
    "Nearest to in: synchronic, paulo, trier, geezer, puerto, scholastic, hamlets, schematics,\n",
    "Nearest to it: big, existentialists, nominations, copious, omissions, component, reddy, nomen,\n",
    "Nearest to these: more, mite, androgen, toolbars, inflated, decibels, zimmermann, practise,\n",
    "Nearest to are: iconic, instructs, tashkent, uninhabitable, philippians, dissenters, proctor, behavioral,\n",
    "Average loss at step  2000 :  114.673232451\n",
    "Average loss at step  4000 :  52.4509469471\n",
    "Average loss at step  6000 :  32.9667173579\n",
    "Average loss at step  8000 :  23.3739907563\n",
    "Average loss at step  10000 :  17.8457111861\n",
    "```\n",
    "\n",
    "（5）用t-SNE降维呈现。这里我们将上一步训练的结果做了一个t-SNE降维处理，最终用Matplotlib绘制出图形，图形见图3-21。代码如下：\n",
    "\n",
    "``` python\n",
    "def plot_with_labels(low_dim_embs, labels, filename):\n",
    "  assert low_dim_embs.shape[0] >= len(labels), 'More labels than embeddings'\n",
    "  plt.figure(figsize=(18, 18))  # in inches\n",
    "  for i, label in enumerate(labels):\n",
    "    x, y = low_dim_embs[i, :]\n",
    "    plt.scatter(x, y)\n",
    "    plt.annotate(\n",
    "        label,\n",
    "        xy=(x, y),\n",
    "        xytext=(5, 2),\n",
    "        textcoords='offset points',\n",
    "        ha='right',\n",
    "        va='bottom')\n",
    "\n",
    "  plt.savefig(filename)\n",
    "\n",
    "\n",
    "try:\n",
    "  # pylint: disable=g-import-not-at-top\n",
    "  from sklearn.manifold import TSNE\n",
    "  import matplotlib.pyplot as plt\n",
    "\n",
    "  tsne = TSNE(\n",
    "      perplexity=30, n_components=2, init='pca', n_iter=5000, method='exact')\n",
    "  plot_only = 500\n",
    "  low_dim_embs = tsne.fit_transform(final_embeddings[:plot_only, :])\n",
    "  labels = [reverse_dictionary[i] for i in xrange(plot_only)]\n",
    "  plot_with_labels(low_dim_embs, labels, os.path.join(gettempdir(), 'tsne.png'))\n",
    "\n",
    "except ImportError as ex:\n",
    "  print('Please install sklearn, matplotlib, and scipy to show embeddings.')\n",
    "  print(ex)\n",
    "```\n",
    "\n",
    "```\n",
    "小知识\n",
    "t-SNE是流形学习（manifold learning）方法的一种。它假设数据是均匀采样于一个高维空间的低维流形，流形学习就是找到高维空间中的低维流形，并求出相应的嵌入映射，以实现维数约简或者数据可视化。流形学习方法分为线性和非线性的两种。线性的流形学习方法如主成分分析（PCA）、非线性的流形学习方法如等距特征映射（Isomap）、拉普拉斯特征映射（Laplacian eigenmaps，LE）、局部线性嵌入（Locally-linear embedding，LLE）等。\n",
    "```\n",
    "\n",
    "### 3.3.2 嵌入投影仪\n",
    "\n",
    "在3.2节中我们说到，在TensorBoard的面板中还有一个EMBEDDINGS面板，用于交互式可视化和分析高维数据。对于上面的word2vec_basic.py文件，我们只是做了一个降维分析，下面我们就来看看TensorBoard在词嵌入中的投影。这里采用官方GitHub开源实现上的例子进行讲解。\n",
    "\n",
    "首先需要下载样例文本和评估数据：\n",
    "\n",
    "```\n",
    "git clone https://github.com/tensorflow/models.git\n",
    "cd models/tutorials/embedding/\n",
    "curl http://mattmahoney.net/dc/text8.zip > text8.zip\n",
    "unzip text8.zip\n",
    "curl https://storage.googleapis.com/google-code-archive-source/v2/code.google.com/word2vec/source-archive.zip > source-archive.zip\n",
    "unzip -p source-archive.zip  word2vec/trunk/questions-words.txt > questions-words.txt\n",
    "rm text8.zip source-archive.zip\n",
    "```\n",
    "\n",
    "然后此处我们自定义了两个操作（operator，OP）：SkipgramWord2vec和NegTrainWord2vec。为什么需要自定义操作以及如何定义一个操作将在4.10节介绍。操作需要先编译，然后执行：\n",
    "\n",
    "```\n",
    "TF_CFLAGS=( $(python -c 'import tensorflow as tf; print(\" \".join(tf.sysconfig.get_compile_flags()))') )\n",
    "TF_LFLAGS=( $(python -c 'import tensorflow as tf; print(\" \".join(tf.sysconfig.get_link_flags()))') )\n",
    "g++ -std=c++11 -shared word2vec_ops.cc word2vec_kernels.cc -o word2vec_ops.so -fPIC ${TF_CFLAGS[@]} ${TF_LFLAGS[@]} -O2 -D_GLIBCXX_USE_CXX11_ABI=0\n",
    "```\n",
    "\n",
    "在当前目录下生成word2vec_ops.so文件，然后执行word2vec_optimized.py：\n",
    "\n",
    "```\n",
    "python word2vec_optimized.py \\\n",
    "  --train_data=text8 \\\n",
    "  --eval_data=questions-words.txt \\\n",
    "  --save_path=/tmp/\n",
    "```\n",
    "\n",
    "生成的模型和日志文件位于/tmp/，我们执行：\n",
    "\n",
    "```\n",
    "tensorboard --logdir=/tmp/\n",
    "```\n",
    "\n",
    "访问```http://localhost.localdomain:6006```，得到的EMBEDDINGS面板如图3-22所示。\n",
    "\n",
    "![3-22](3-attach/3-22.png)\n",
    "\n",
    "在EMBEDDINGS面板左侧的工具栏中，可以选择降维的方式，有T-SNE、PCA和CUSTOM的降维方式，并且可以做二维/三维的图像切换。例如，切换到t-SNE降维工具，可以手动调整Dimension（维度）、Learning rate（学习率）等参数，最终生成10,000个点的分布，如图3-23所示。\n",
    "\n",
    "![3-23](3-attach/3-23.png)\n",
    "\n",
    "在EMBEDDINGS面板的右侧，可以采用正则表达式匹配出某些词，直观地看到词之间的余弦距离或欧式距离的关系，如图3-24所示。\n",
    "\n",
    "![3-24](3-attach/3-24.png)\n",
    "\n",
    "任意选择一个点，如8129，选择“isolate 101 points”按钮，将会展示出100个在空间上最接近被选择点的词，也可以调整展示的词的数量，如图3-25所示。\n",
    "\n",
    "![3-25](3-attach/3-25.png)\n",
    "\n",
    "## 3.4 小结\n",
    "\n",
    "可视化是研究深度学习的一个重要方向，有利于我们直观地探究训练过程中的每一步发生的变化。TensorFlow提供了强大的工具TensorBoard，不仅有完善的API接口，而且提供的面板也非常丰富。在4.3.2节我们会讲解实现TensorBoard的API。在第17章我们还会讲到TensorFlow的调试工具，调试和可视化配合起来，有利于精准地调整模型。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
